{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc3199c-3b62-4839-b367-d6da323bcb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/mnt/home/cpedersen/Codes/cancer-net/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a309c2-bf81-4d58-8fd1-3354f9cef755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import TCGAData\n",
    "import torch, torch_geometric.transforms as T, torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt, numpy as np\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from arch.net import *\n",
    "import wandb\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282dc9bf-f3ac-4900-b79d-0959bca60874",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Objective(object):\n",
    "    def __init__(self,arch,root,rng,batch,epochs,device):\n",
    "        self.arch=arch\n",
    "        self.root=root\n",
    "        self.rng=rng\n",
    "        self.batch=batch\n",
    "        self.epochs=epochs\n",
    "        self.device=device\n",
    "        \n",
    "        ## hardcoding this false for now\n",
    "        self.parall=False\n",
    "        \n",
    "        ## Should be able to construct the dataset before __call__\n",
    "        ## as this won't change for different trials\n",
    "        label_mapping = [\"LGG\", \"GBM\"]\n",
    "        self.dataset = TCGAData.TCGADataset(\n",
    "            root=self.root,\n",
    "            files=self.root+\"/samples.txt\",\n",
    "            label_mapping=label_mapping,\n",
    "            gene_graph=\"brain.geneSymbol.gz\",\n",
    "        )\n",
    "\n",
    "        rng = np.random.default_rng(self.rng)\n",
    "        rnd_perm = rng.permutation(len(self.dataset))\n",
    "        self.train_indices = list(rnd_perm[: 3 * len(self.dataset) // 4])\n",
    "        self.test_indices = list(rnd_perm[3 * len(self.dataset) // 4 :])\n",
    "        self.train_loader = DataLoader(\n",
    "            self.dataset,\n",
    "            batch_size=self.batch,\n",
    "            sampler=SubsetRandomSampler(self.train_indices),\n",
    "            drop_last=True,\n",
    "        )\n",
    "        self.test_loader = DataLoader(\n",
    "            self.dataset,\n",
    "            batch_size=self.batch,\n",
    "            sampler=SubsetRandomSampler(self.test_indices),\n",
    "            drop_last=True,\n",
    "        )\n",
    "\n",
    "        assert len(self.train_indices) + len(self.test_indices) == len(\n",
    "            self.dataset\n",
    "        ), \"Train test split with overlap or unused samples!\"\n",
    "    \n",
    "    def train(self, epoch, report=True):\n",
    "        self.model.train()\n",
    "\n",
    "        if epoch == 30:\n",
    "            for param_group in self.optimizer.param_groups:\n",
    "                param_group[\"lr\"] = self.lr * 0.5\n",
    "\n",
    "        if epoch == 60:\n",
    "            for param_group in self.optimizer.param_groups:\n",
    "                param_group[\"lr\"] = self.lr * 0.1\n",
    "\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        num_samps = 0\n",
    "        for data in self.train_loader:\n",
    "            if not self.parall:\n",
    "                data = data.to(device)\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            output = self.model(data)\n",
    "            output = output.squeeze()\n",
    "\n",
    "            if self.parall:\n",
    "                y = torch.cat([d.y for d in data]).to(output.device)\n",
    "            else:\n",
    "                y = data.y\n",
    "\n",
    "            if len(output.shape) == 1:\n",
    "                output = output.unsqueeze(0)\n",
    "            loss = self.criterion(output, y)\n",
    "\n",
    "            pred = output.max(1)[1]\n",
    "            correct += pred.eq(y).sum().item()\n",
    "            total_loss += loss\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            num_samps += len(y)\n",
    "        if report:\n",
    "            print(\n",
    "                \"Epoch: {:02d}, Loss: {:.3g}, Train Acc: {:.4f}\".format(\n",
    "                    epoch, total_loss / num_samps, correct / num_samps\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return total_loss / num_samps, correct / num_samps\n",
    "    \n",
    "    def test(self):\n",
    "        self.model.eval()\n",
    "        correct = 0\n",
    "\n",
    "        total_loss = 0\n",
    "        num_samps = 0\n",
    "        for data in self.test_loader:\n",
    "            if not self.parall:\n",
    "                data = data.to(device)\n",
    "            output = self.model(data)\n",
    "            output = output.squeeze()\n",
    "\n",
    "            pred = output.max(1)[1]\n",
    "            if self.parall:\n",
    "                y = torch.cat([d.y for d in data]).to(output.device)\n",
    "            else:\n",
    "                y = data.y\n",
    "            loss = self.criterion(output, y)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            correct += pred.eq(y).sum().item()\n",
    "            num_samps += len(y)\n",
    "        return total_loss / num_samps, correct / num_samps\n",
    "    \n",
    "    def __call__(self,trial):\n",
    "        print(\"Suggesting trial\")\n",
    "        # get the value of the hyperparameters\n",
    "        self.lr = trial.suggest_float(\"lr\", 1e-5, 5e-2, log=True)\n",
    "        #wd     = trial.suggest_float(\"wd\", 1e-8, 1e-1, log=True)\n",
    "        #dr     = trial.suggest_float(\"dr\", 0.0,  0.9)\n",
    "        print(\"Suggested trial\")\n",
    "        ## Store hyperparams in a config for wandb\n",
    "        config = {\"learning rate\": self.lr,\n",
    "                 \"epochs\": self.epochs,\n",
    "                 \"batch size\": self.batch,\n",
    "                 \"arch\": self.arch}\n",
    "\n",
    "        print('\\nTrial number: {}'.format(trial.number))\n",
    "        print('lr: {}'.format(self.lr))\n",
    "        wandb.login()\n",
    "        wandb.init(project=\"brain-test\", entity=\"chris-pedersen\",config=config)\n",
    "        self.model = GCNNet().to(device)\n",
    "        wandb.watch(self.model, log_freq=1)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        self.criterion = F.nll_loss\n",
    "        train_losses = []\n",
    "        train_acces = []\n",
    "        test_acces = []\n",
    "        test_losses = []\n",
    "        for epoch in range(1, self.epochs):\n",
    "            report = (epoch) % 10 == 0\n",
    "            train_loss, train_acc = self.train(epoch, report=report)\n",
    "            test_loss, test_acc = self.test()\n",
    "            train_losses.append(train_loss.cpu().detach().numpy())\n",
    "            test_losses.append(test_loss)\n",
    "            train_acces.append(train_acc)\n",
    "            test_acces.append(test_acc)\n",
    "            wandb.log({\"train loss\": train_loss,\n",
    "                       \"test loss\": test_loss,\n",
    "                       \"train accuracy\": train_acc,\n",
    "                       \"test accuracy\": test_acc})\n",
    "            if report:\n",
    "                print(\"Test Loss: {:.3g}, Acc: {:.4f}\".format(test_loss, test_acc))\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541f936e-7245-4fde-9901-9bc69eae02c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = \"GCN\"\n",
    "batch = 10\n",
    "rng = 2022\n",
    "parall = False\n",
    "epochs=100\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "root = \"/mnt/home/sgolkar/projects/cancer-net/data/brain\"\n",
    "\n",
    "## Optuna params\n",
    "study_name = \"optuna/brain_test\"  # Unique identifier of the study.\n",
    "storage_name = \"sqlite:///{}.db\".format(study_name)\n",
    "n_trials=10\n",
    "\n",
    "# train networks with bayesian optimization\n",
    "objective = Objective(arch,root,rng,batch,epochs,device)\n",
    "sampler = optuna.samplers.TPESampler(n_startup_trials=20)\n",
    "study = optuna.create_study(study_name=study_name, sampler=sampler, storage=storage_name,\n",
    "                            load_if_exists=True)\n",
    "study.optimize(objective, n_trials, gc_after_trial=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68618ef8-76e8-43d1-b73e-8edf1e3bf1da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4ba570-39e1-4534-8f92-6a8361d27f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training on brain data using GCN architecture\n",
    "\n",
    "# Hyperparameters etc:\n",
    "\n",
    "arch = \"GCN\"\n",
    "batch = 10\n",
    "parall = False\n",
    "lr = 0.005\n",
    "\n",
    "root = \"/mnt/home/sgolkar/projects/cancer-net/data/brain\"\n",
    "files = \"/mnt/home/sgolkar/projects/cancer-net/data/brain/samples.txt\"\n",
    "label_mapping = [\"LGG\", \"GBM\"]\n",
    "dataset = TCGAData.TCGADataset(\n",
    "    root=root,\n",
    "    files=files,\n",
    "    label_mapping=label_mapping,\n",
    "    gene_graph=\"brain.geneSymbol.gz\",\n",
    ")\n",
    "\n",
    "rng = np.random.default_rng(2022)\n",
    "rnd_perm = rng.permutation(len(dataset))\n",
    "train_indices = list(rnd_perm[: 3 * len(dataset) // 4])\n",
    "test_indices = list(rnd_perm[3 * len(dataset) // 4 :])\n",
    "train_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch,\n",
    "    sampler=SubsetRandomSampler(train_indices),\n",
    "    drop_last=True,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch,\n",
    "    sampler=SubsetRandomSampler(test_indices),\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "assert len(train_indices) + len(test_indices) == len(\n",
    "    dataset\n",
    "), \"Train test split with overlap or unused samples!\"\n",
    "\n",
    "model = GCNNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = F.nll_loss\n",
    "\n",
    "\n",
    "def train(epoch, report=True):\n",
    "    model.train()\n",
    "\n",
    "    if epoch == 30:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group[\"lr\"] = lr * 0.5\n",
    "\n",
    "    if epoch == 60:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group[\"lr\"] = lr * 0.1\n",
    "\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    num_samps = 0\n",
    "    for data in train_loader:\n",
    "        if not parall:\n",
    "            data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(data)\n",
    "        output = output.squeeze()\n",
    "\n",
    "        if parall:\n",
    "            y = torch.cat([d.y for d in data]).to(output.device)\n",
    "        else:\n",
    "            y = data.y\n",
    "\n",
    "        if len(output.shape) == 1:\n",
    "            output = output.unsqueeze(0)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        pred = output.max(1)[1]\n",
    "        correct += pred.eq(y).sum().item()\n",
    "        total_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        num_samps += len(y)\n",
    "    if report:\n",
    "        print(\n",
    "            \"Epoch: {:02d}, Loss: {:.3g}, Train Acc: {:.4f}\".format(\n",
    "                epoch, total_loss / num_samps, correct / num_samps\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return total_loss / num_samps, correct / num_samps\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "\n",
    "    total_loss = 0\n",
    "    num_samps = 0\n",
    "    for data in test_loader:\n",
    "        if not parall:\n",
    "            data = data.to(device)\n",
    "        output = model(data)\n",
    "        output = output.squeeze()\n",
    "\n",
    "        pred = output.max(1)[1]\n",
    "        if parall:\n",
    "            y = torch.cat([d.y for d in data]).to(output.device)\n",
    "        else:\n",
    "            y = data.y\n",
    "        loss = criterion(output, y)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        correct += pred.eq(y).sum().item()\n",
    "        num_samps += len(y)\n",
    "    return total_loss / num_samps, correct / num_samps\n",
    "\n",
    "\n",
    "train_losses = []\n",
    "train_acces = []\n",
    "test_acces = []\n",
    "test_losses = []\n",
    "for epoch in range(1, 101):\n",
    "    report = (epoch) % 10 == 0\n",
    "    train_loss, train_acc = train(epoch, report=report)\n",
    "    test_loss, test_acc = test()\n",
    "    train_losses.append(train_loss.cpu().detach().numpy())\n",
    "    test_losses.append(test_loss)\n",
    "    train_acces.append(train_acc)\n",
    "    test_acces.append(test_acc)\n",
    "    if report:\n",
    "        print(\"Test Loss: {:.3g}, Acc: {:.4f}\".format(test_loss, test_acc))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_acces, label=\"train acc\", linewidth=3)\n",
    "plt.plot(test_acces, label=\"test acc\", linewidth=3)\n",
    "plt.legend(prop={\"size\": 16})\n",
    "plt.xlabel(\"epoch\", fontsize=16)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.plot(train_losses, c=\"tab:blue\", label=\"train loss\", linewidth=3)\n",
    "plt.plot(test_losses, c=\"tab:orange\", label=\"test loss\", linewidth=3)\n",
    "plt.legend(prop={\"size\": 16})\n",
    "plt.xlabel(\"epoch\", fontsize=16)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "## Below is for populating ROC curve I think\n",
    "loader_auc = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch,\n",
    "    sampler=SubsetRandomSampler(train_indices),\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "outs = []\n",
    "ys = []\n",
    "for tb in loader_auc:\n",
    "    tbc = tb.cuda()\n",
    "    outs.append(torch.exp(model(tb)))\n",
    "    ys.append(tb.y)\n",
    "\n",
    "outs = torch.cat(outs).cpu().data.numpy()\n",
    "ys = torch.cat(ys).cpu().data.numpy()\n",
    "\n",
    "fpr_train, tpr_train, _ = roc_curve(ys, outs[:, 1])\n",
    "train_auc = auc(fpr_train, tpr_train)\n",
    "\n",
    "loader_auc = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch,\n",
    "    sampler=SubsetRandomSampler(test_indices),\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "outs = []\n",
    "ys = []\n",
    "for tb in loader_auc:\n",
    "    tbc = tb.cuda()\n",
    "    outs.append(torch.exp(model(tb)))\n",
    "    ys.append(tb.y)\n",
    "\n",
    "outs = torch.cat(outs).cpu().data.numpy()\n",
    "ys = torch.cat(ys).cpu().data.numpy()\n",
    "\n",
    "fpr_test, tpr_test, _ = roc_curve(ys, outs[:, 1])\n",
    "test_auc = auc(fpr_test, tpr_test)\n",
    "\n",
    "plt.plot(\n",
    "    fpr_train, tpr_train, lw=2, label=\"ROC curve (area = %0.3f)\" % train_auc,\n",
    ")\n",
    "plt.plot(\n",
    "    fpr_test, tpr_test, lw=2, label=\"ROC curve (area = %0.3f)\" % test_auc,\n",
    ")\n",
    "plt.plot([0, 1], [0, 1], color=\"black\", lw=1, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver operating characteristic\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cf4262-4490-4e16-825b-5271499fb412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fdfb0f-8dfe-4ac2-898a-5ac71c17e1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4a2c99-fb19-45f7-9d29-f91757ca7090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f990514-fc8a-4b16-9f20-636b027af87c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cancerenv",
   "language": "python",
   "name": "cancerenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
