{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fed5cf92-1812-4455-909a-e4aaf74d8cd5",
   "metadata": {},
   "source": [
    "## Edges\n",
    "\n",
    "Inspect our graph and subgraphs to get a better idea of how connected our nodes are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b5a08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db70bf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pnet_utils\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch, torch_geometric.transforms as T, torch.nn.functional as F\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch_geometric.utils import subgraph\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, average_precision_score, f1_score, accuracy_score, \\\n",
    "    precision_score, recall_score\n",
    "\n",
    "import torch, torch_geometric.transforms as T, torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.nn import Sequential as Seq, Linear as Lin, ReLU, BatchNorm1d\n",
    "from torch_scatter import scatter_mean, scatter_add\n",
    "from torch_geometric.nn import MetaLayer\n",
    "from torch_geometric.nn import global_mean_pool, global_max_pool, GlobalAttention\n",
    "\n",
    "%run arch/net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758dfaad-042a-4816-ac2f-81009833fb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeModel(torch.nn.Module):\n",
    "    def __init__(self,node_size,edge_attr_size,hidden):\n",
    "        super(EdgeModel, self).__init__()\n",
    "        self.edge_mlp = Seq(Lin(node_size*2+edge_attr_size, hidden),\n",
    "                            ReLU(),\n",
    "                            Lin(hidden, hidden))\n",
    "\n",
    "    def forward(self, src, dest, edge_attr, u, batch):\n",
    "        \"\"\"\n",
    "         Function to update edge attribtes. Takes as input:\n",
    "             - src: [E, F_x]  where E is the number of edges, F_x are the node features\n",
    "                              of the sending node.\n",
    "             - dest: [E, F_x] the node features for the \"receiving\" nodes.\n",
    "             - edge_attr: [E, F_e] where F_e are the edge features.\n",
    "             - u: global features, not currently used.\n",
    "             - batch: [E] with max entry B - 1.\n",
    "        \n",
    "         returns: [E, F_h] where F_h is the size of the hidden layers. These constitute\n",
    "                           the updated edge features after a \"message pass\" step.\n",
    "        \"\"\"\n",
    "        if len(edge_attr.shape)==1:\n",
    "            out = torch.cat([src, dest, edge_attr.reshape(-1, 1)], 1)\n",
    "        else:\n",
    "            out = torch.cat([src, dest, edge_attr], 1)\n",
    "        return self.edge_mlp(out)\n",
    "\n",
    "    \n",
    "class NodeModel(torch.nn.Module):\n",
    "    def __init__(self,input_size,hidden):\n",
    "        super(NodeModel, self).__init__()\n",
    "        self.message_function = Seq(Lin(input_size+hidden, hidden),\n",
    "                              ReLU(), \n",
    "                              Lin(hidden, hidden),\n",
    "                              ReLU(),\n",
    "                              Lin(hidden, hidden))\n",
    "        self.node_mlp = Seq(Lin(input_size+hidden, hidden),\n",
    "                              ReLU(), \n",
    "                              Lin(hidden, hidden),\n",
    "                              ReLU(),\n",
    "                              Lin(hidden, hidden))\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, u, batch):\n",
    "        \"\"\"\n",
    "         Update node attributes - takes node features & edge features, updates node features\n",
    "         based on the features of the sending and receiving node, and edge features of each connection.\n",
    "             - x: [N, F_x] where N is the number of nodes, F_x are the node features. NB that\n",
    "                           F_x can be different for different layers of the graph (i.e. the input\n",
    "                           feature size is currently 3, while the latent node feature size is\n",
    "                           of size `hidden`.\n",
    "             - edge_index: [2,E] where E is the number of edges. List of indices describing the sending\n",
    "                                 and receiving nodes of each edge.\n",
    "             - edge_attr: [E, F_e] where F_e are the edge features. NB this can also be different\n",
    "                                   for different layers.\n",
    "             - u: Global features, not currently used.\n",
    "             - batch: [E] with max entry B - 1.\n",
    "        \n",
    "         returns: [N, F_h] where F_h is the size of the hidden layers.\n",
    "        \"\"\"\n",
    "        send_idx, rec_idx = edge_index ## Indices of sending and receiving nodes\n",
    "        out = torch.cat([x[send_idx], edge_attr], dim=1) ## Tensor of node features of sending nodes, concatenated with the edge features\n",
    "        out = self.message_function(out)\n",
    "        out = scatter_add(out, rec_idx, dim=0, dim_size=x.size(0)) ## Aggregation step - for each receiving node, take the average of the hidden layer outputs connected to that node\n",
    "        ## Finally concat each node feature with the hidden layer outputs, pass to one final MLP\n",
    "        return self.node_mlp(torch.cat([x, out], dim=1)) \n",
    "    \n",
    "\n",
    "class GlobalModel(torch.nn.Module):\n",
    "    def __init__(self, hidden, outputs):\n",
    "        super(GlobalModel, self).__init__()\n",
    "        self.global_mlp = Seq(Lin(hidden, hidden),\n",
    "                              BatchNorm1d(hidden),\n",
    "                              ReLU(),\n",
    "                              Lin(hidden, outputs))\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, u, batch):\n",
    "        \"\"\"\n",
    "         Aggregate node features. Global mean pool, then pass the pooled features\n",
    "         to a MLP.\n",
    "        \"\"\"\n",
    "        out = scatter_mean(x, batch, dim=0)\n",
    "        out = self.global_mlp(out)\n",
    "        return out\n",
    "\n",
    "    \n",
    "class InteractionNetworkMulti(torch.nn.Module):\n",
    "    def __init__(self,layers,hidden):\n",
    "        \"\"\"\n",
    "         Class to stack multiple MetaLayers\n",
    "            - layers: Number of MetaLayer graphs to construct\n",
    "            - hidden: Sets the latent space size of the edge, node, and global model MLPs.\n",
    "                      This also sets the size of the latent space representation of the edge\n",
    "                      and node features after a single MetaLayer pass.\n",
    "                      \n",
    "        The general procedure for the MetaLayer is as follows.\n",
    "            1. The EdgeModel takes the node features and edge features. For each edge connection,\n",
    "               the node and edge features for each edge are concatenated together and passed to\n",
    "               an MLP. The output is then a set of u pdated node features.\n",
    "            2. The NodeModel takes the updated edge features, concatenates them each with the \n",
    "               node features of the *sending* node, and passes this tensor to an MLP.\n",
    "               For each receiving node, the output of this MLP is then summed over in an aggregation step.\n",
    "               These aggregated features are then concatenated with the features of the receiving node, and\n",
    "               passed to another MLP. The output of this MLP then constitutes the updated node features\n",
    "            3. The global model is a simple global pooling of the node features, which are then passed to an MLP\n",
    "            \n",
    "        For multiple \"stacks\" of graphs, steps 1 and 2 are repeated. Step 3 is only used for the final output of the graph.\n",
    "        \"\"\"\n",
    "        super(InteractionNetworkMulti, self).__init__()\n",
    "        self.layers=layers\n",
    "        ## List for multiple graph layers\n",
    "        self.graphs=nn.ModuleList()\n",
    "        self.graphs.append(MetaLayer(EdgeModel(3,1,hidden), NodeModel(3,hidden), GlobalModel(hidden,1)))\n",
    "        ## Add multiple graph layers\n",
    "        for aa in range(self.layers-1):\n",
    "            self.graphs.append(MetaLayer(EdgeModel(hidden,hidden,hidden), NodeModel(hidden,hidden), GlobalModel(hidden,1)))\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_attr, u, batch):\n",
    "        x, edge_attr, u = self.graphs[0](x, edge_index, edge_attr, None, batch)\n",
    "        for aa in range(1,self.layers):\n",
    "            x, edge_attr, u = self.graphs[aa](x, edge_index, edge_attr, None, batch)\n",
    "        return u\n",
    "\n",
    "    \n",
    "class InteractionSubSystem(torch.nn.Module):\n",
    "    def __init__(self, model_config=None, activation=None, node_subset=None, max_nodes=None):\n",
    "        \"\"\"\n",
    "         Class to build subgraphs based on Pnet biological subprocesses, and pass these subgraphs\n",
    "         as input to an InteractionNetworkMulti\n",
    "        \"\"\"\n",
    "        super(InteractionSubSystem, self).__init__()\n",
    "        # Note: this assumes each graph has the same number of max_nodes\n",
    "        #self.node_subset = [n+max_nodes*i for i in range(batch) for n in node_subset]\n",
    "        self.node_subset =  np.array(node_subset)\n",
    "        self.max_nodes = max_nodes\n",
    "        self.activation_fn = activation\n",
    "        self.interactionnetwork  = InteractionNetworkMulti(layers=model_config.get(\"layers\"), hidden=model_config.get(\"hidden\"))\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        if self.node_subset is not None:\n",
    "            bs = int(batch.max()) + 1\n",
    "            assert batch.shape[0] == bs*self.max_nodes\n",
    "            batch_subset = np.concatenate([self.node_subset+self.max_nodes*i for i in range(bs)], axis=0).tolist()\n",
    "            edge_index, edge_attr = subgraph(subset=batch_subset, edge_index=edge_index, edge_attr=edge_attr, relabel_nodes=True)\n",
    "            x = x[batch_subset]\n",
    "            batch = batch[batch_subset]\n",
    "        u = self.interactionnetwork(x, edge_index, edge_attr, None, batch)\n",
    "        if self.activation_fn is not None:\n",
    "            u = self.activation_fn(u)\n",
    "        return u\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1124cab9-b45b-49e7-a2b4-3754b6480cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_nd(indices: torch.Tensor, updates: torch.Tensor, shape) -> torch.Tensor:\n",
    "    ind1d = indices[:, 0]\n",
    "    n = shape[0]\n",
    "    for i in range(1, len(shape)):\n",
    "        ind1d = ind1d * shape[i] + indices[:, i]\n",
    "        n *= shape[i]\n",
    "    ind1d.to(device)\n",
    "    updates.to(device)\n",
    "    zz=torch.zeros(n,device=torch.device(device))\n",
    "    result = zz.scatter_add_(0, ind1d, updates).reshape(*shape)\n",
    "    return result\n",
    "\n",
    "class VisibleDense(torch.nn.Module):\n",
    "    def __init__(self, pathway_map, activation=None, use_bias=True):\n",
    "        super(VisibleDense, self).__init__()\n",
    "        ## Import gene pathway map\n",
    "        if isinstance(pathway_map, pd.DataFrame):\n",
    "            self.map = pathway_map.to_numpy().astype(np.float32)\n",
    "        else:\n",
    "            self.map = pathway_map.astype(np.float32)\n",
    "        self.units = self.map.shape[1]\n",
    "        self.input_dim = self.map.shape[0]\n",
    "        self.use_bias = use_bias\n",
    "        ## Identify indices where we have connections\n",
    "        self.nonzero_ind = torch.LongTensor(np.array(np.nonzero(self.map)).T).to(device)\n",
    "        nonzero_count = self.nonzero_ind.shape[0]\n",
    "        ## Builds a tensor of parameters to hold the nonzero weights\n",
    "        self.kernel_vector = torch.nn.Parameter(torch.zeros(nonzero_count,)).to(device)\n",
    "        self.kernel_vector.to(device)\n",
    "        ## Potentially problematic line - distributes the nonzero indices to a matrix of zeroes\n",
    "        \n",
    "        ## Builds a tensor to hold the biases\n",
    "        self.bias = torch.nn.Parameter(data=torch.zeros(self.units,))\n",
    "        ## Initialise the weights and biases\n",
    "        torch.nn.init.uniform_(self.kernel_vector, -0.01, 0.01)\n",
    "        torch.nn.init.uniform_(self.bias, -0.01, 0.01)\n",
    "        self.activation_fn = activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        indices = tf.constant([[0,0], [0,1], [1,1], [2,2]])\n",
    "        updates = tf.constant([9, 10, 11, 12])\n",
    "        shape = tf.constant([3,3])\n",
    "        scatter = tf.scatter_nd(indices, updates, shape)\n",
    "        print(scatter)\n",
    "        tf.Tensor(\n",
    "        [[ 9 10  0]\n",
    "         [ 0 11  0]\n",
    "         [ 0  0 12]], shape=(3, 3), dtype=int32)\n",
    "        '''\n",
    "        device = self.kernel_vector.device\n",
    "        self.kernel = scatter_nd(self.nonzero_ind, self.kernel_vector, shape=(self.input_dim, self.units))\n",
    "        ## Multiply input vector with the sparse matrix\n",
    "        out = torch.matmul(x, self.kernel.to(device))\n",
    "        if self.use_bias:\n",
    "            out = out + self.bias\n",
    "        if self.activation_fn is not None:\n",
    "            out = self.activation_fn(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class VisibleGraphInteractionNet(torch.nn.Module):\n",
    "    def __init__(self, pathway_maps, node_index, model_config=None,sparse=False):\n",
    "        \"\"\"\n",
    "         Model that combines a stack of MetaLayers composed of subgraphs with a final neural layer.\n",
    "             - sparse: if False, uses a single fully connected layer after the graph outputs.\n",
    "                       if True, uses sparse connections for the final layer, based off Pnet masks.\n",
    "        \"\"\"\n",
    "        super(VisibleGraphInteractionNet, self).__init__()\n",
    "        self.model_config = model_config\n",
    "        self.pathway_maps = pathway_maps\n",
    "        self.node_index = node_index\n",
    "        self.pathway_to_nodes = self.get_node_subset()\n",
    "        self.subsys = torch.nn.ModuleList([\n",
    "                InteractionSubSystem(\n",
    "                    model_config = self.model_config,\n",
    "                    node_subset = self.pathway_to_nodes[target_pathway],\n",
    "                    max_nodes = len(self.node_index)\n",
    "                    )\n",
    "                for target_pathway in self.pathway_maps[0].columns\n",
    "                ])\n",
    "        hidden = self.pathway_maps[1].shape[1]\n",
    "        if sparse==False:\n",
    "            self.nn = Seq(\n",
    "                Lin(len(self.subsys), hidden),\n",
    "                ReLU(),\n",
    "                Lin(hidden,2)\n",
    "            )\n",
    "        else:\n",
    "            self.nn = Seq(\n",
    "                VisibleDense(pathway_map=self.pathway_maps[1]),\n",
    "                ReLU(),\n",
    "                Lin(hidden,2)\n",
    "            )\n",
    "\n",
    "\n",
    "    def get_node_subset(self):\n",
    "        pathway_to_nodes = {}\n",
    "        for target_pathway in self.pathway_maps[0].columns:\n",
    "            subset = [self.pathway_maps[0].index[i] for i, g in enumerate(self.pathway_maps[0][target_pathway]) if g==1]\n",
    "            subset = sorted([self.node_index[g] for g in subset])\n",
    "            pathway_to_nodes[target_pathway] = subset\n",
    "        return pathway_to_nodes\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        h = torch.cat([g(x, edge_index, edge_attr, batch) for g in self.subsys], dim=-1)\n",
    "        out = self.nn(h)\n",
    "        return F.log_softmax(out, dim=-1)\n",
    "    \n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b060b249-5a2e-4c8d-91f9-633a5a241794",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rootdir=\"/mnt/home/zzhang/ceph/cancer-net/\"\n",
    "\n",
    "reactome_kws = dict(\n",
    "    reactome_base_dir = data_rootdir+'/pnet/_database/pathways/Reactome',\n",
    "    relations_file_name = 'ReactomePathwaysRelation.txt',\n",
    "    pathway_names_fn = 'ReactomePathways.txt',\n",
    "    pathway_genes_fn = 'ReactomePathways.gmt',\n",
    ")\n",
    "reactome = pnet_utils.ReactomeNetwork(reactome_kws)\n",
    "\n",
    "dataset = pnet_utils.PnetDataSet(\n",
    "    root=data_rootdir+\"/data/prostate\",\n",
    "    name=\"prostate_graph_humanbase\",\n",
    "    edge_tol=0.5,\n",
    "    pre_transform=T.Compose([T.GCNNorm(add_self_loops=False), T.ToSparseTensor(remove_edge_index=False)]))\n",
    "\n",
    "## loads the train/valid/test split from pnet\n",
    "dataset.split_index_by_file(\n",
    "    train_fp=data_rootdir+\"/data/prostate/splits/training_set_0.csv\",\n",
    "    valid_fp=data_rootdir+\"/data/prostate/splits/validation_set.csv\",\n",
    "    test_fp=data_rootdir+\"/data/prostate/splits/test_set.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335091cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "maps = pnet_utils.get_layer_maps(\n",
    "    genes=[g for g in dataset.node_index],\n",
    "    reactome=reactome,\n",
    "    n_levels=2,\n",
    "    direction='root_to_leaf',\n",
    "    add_unk_genes=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faeca184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use only top subsys\n",
    "#n_top = 12\n",
    "#maps[0] = maps[0][maps[0].sum(axis=0).sort_values(ascending=False).head(n_top).index]\n",
    "#maps[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443c5a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "maps[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c91219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3a5397",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 10\n",
    "\n",
    "# prep data\n",
    "train_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch,\n",
    "    sampler=SubsetRandomSampler(dataset.train_idx),\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch,\n",
    "    sampler=SubsetRandomSampler(dataset.valid_idx),\n",
    "    drop_last=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434059db",
   "metadata": {},
   "outputs": [],
   "source": [
    "parall = False\n",
    "lr = 0.001  ## Learning rate\n",
    "inputs = 3  ## Input node feature size\n",
    "outputs = 1 ## Output dimensions of each subgraph\n",
    "hidden = 16 ## Size of hidden layers in graphs (both the MLP size and latent representation of nodes and edge)\n",
    "layers = 2  ## Number of graphs to stack\n",
    "\n",
    "model = VisibleGraphInteractionNet(\n",
    "    pathway_maps = maps,\n",
    "    node_index = dataset.node_index,\n",
    "    #edge_model=edge_model, node_model=node_model, global_model=global_model,\n",
    "    model_config = {'inputs':inputs, 'outputs':outputs, 'hidden':hidden, 'layers':layers},\n",
    "    sparse=False\n",
    ").to(device)\n",
    "\n",
    "print(count_parameters(model),\"learnable parameters in model\")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=3)\n",
    "criterion = F.nll_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e132f01-aabc-4906-9b6d-6265efa1c346",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get numbers of nodes and edges present in each subgraph\n",
    "num_total_nodes=int(dataset.data.num_nodes/len(dataset.indices()))\n",
    "num_edges=int(len(dataset.data.edge_attr)/len(dataset.indices()))\n",
    "edge_indices=dataset.data.edge_index[:,0:num_edges]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ab684e-5197-45a9-b65e-a49724352b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_count_full=np.zeros(num_total_nodes)\n",
    "for aa in range(len(edge_indices[0])):\n",
    "    ## Count how many times each node index appears as an edge connection\n",
    "    edge_count_full[int(edge_indices[0][aa])]+=1\n",
    "print(\"number of nodes with zero edges:\",np.count_nonzero(edge_count_full==0))\n",
    "print(\"number of nodes with one edgee:\",np.count_nonzero(edge_count_full==1))\n",
    "print(\"most edges for a single node:\",np.max(edge_count_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b471b4f-2c30-4f9c-8a56-6b361bd13ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.hist(np.array(edge_count_full),bins=100);\n",
    "plt.xlabel(\"Number of edge connections for a single node\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bfa5bf-02c0-4083-8a95-c3e370c87552",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get numbers of nodes and edges present in each subgraph\n",
    "num_nodes=maps[0].sum(axis=0).sort_values(ascending=False).to_numpy()\n",
    "\n",
    "## Indices of subgraphs, from largest to smallest\n",
    "indices=np.flip(np.argsort(maps[0].sum(axis=0).to_numpy()))\n",
    "\n",
    "## Number of total edges in master graph\n",
    "all_edges=int(len(dataset.data.edge_attr)/len(dataset.indices()))\n",
    "\n",
    "edge_count=[]\n",
    "for index in indices:\n",
    "    edge_index, edge_attr = subgraph(model.pathway_to_nodes[list(model.pathway_to_nodes.keys())[index]], edge_attr=dataset.data.edge_attr[0:num_edges], edge_index=dataset.data.edge_index[:,0:num_edges], relabel_nodes=True)\n",
    "    edge_count.append(len(edge_attr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ef2e1d-6f76-426d-8c28-7254d7afeede",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(num_nodes,\"o\",label=\"# nodes in subgraph\")\n",
    "plt.plot(edge_count,\"+\",color=\"red\",label=\"# edges in subgraph\")\n",
    "plt.ylabel(\"Number of nodes & edges\")\n",
    "plt.xlabel(\"Subgraph #\")\n",
    "plt.axhline(0,color=\"gray\")\n",
    "plt.legend()\n",
    "#plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66be509e-f86a-4070-8815-e0613c4f0ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cancerenv",
   "language": "python",
   "name": "cancerenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
